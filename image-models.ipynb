{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EFFICIENTNETB0 MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Define dataset path\n",
    "DATASET_PATH = \"/kaggle/input/glaucomadataset-healthy-and-infected-images/datasets combined/\"\n",
    "\n",
    "# Image Augmentation to increase dataset size\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load dataset\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,  # Smaller batch size for small datasets\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = train_datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=8,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load EfficientNetB0 Pre-trained Model\n",
    "base_model = EfficientNetB0(\n",
    "    weights=\"/kaggle/input/efficientnetb0-notop-h5/efficientnetb0_notop.h5\",\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Add Custom Layers on top\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.4)(x)  # Reduce overfitting\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)  # More dropout\n",
    "output = Dense(1, activation=\"sigmoid\")(x)  # Binary classification\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save(\"glaucoma_model.keras\")\n",
    "\n",
    "print(\"Training completed and model saved!\")\n",
    "\n",
    "# Compute the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Make predictions on the validation set\n",
    "predicted_classes_efficientnet = model.predict(X_test)  # Replace cnn_model with your actual CNN model variable\n",
    "predicted_classes_efficientnet = np.argmax(predicted_classes_efficientnet, axis=1)  # In case of multi-class classification, use argmax\n",
    "\n",
    "efficientnet_accuracy = accuracy_score(y_test, predicted_classes_cnn)  # Now using the defined predicted_classes_cnn\n",
    "efficientnet_report = classification_report(y_test, predicted_classes_efficientnet, output_dict=True)\n",
    "efficientnet_precision = efficientnet_report['accuracy']\n",
    "efficientnet_recall = efficientnet_report['macro avg']['recall']\n",
    "efficientnet_f1 = efficientnet_report['macro avg']['f1-score']\n",
    "\n",
    "# Add the results to the list\n",
    "results.append({\n",
    "    \"Model\": \"efficientnet\",\n",
    "    \"Accuracy\": efficient_accuracy,\n",
    "    \"Precision\": efficient_precision,\n",
    "    \"Recall\": efficient_recall,\n",
    "    \"F1-Score\": efficient_f1\n",
    "})\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MOBILENETV2 MODEL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "\n",
    "# Define paths\n",
    "data_dir = \"/kaggle/input/glaucomadataset-healthy-and-infected-images/datasets combined\"\n",
    "\n",
    "# Image Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Load Training and Validation Data\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Load MobileNetV2 Pre-trained Model\n",
    "base_model = MobileNetV2(weights=\"/kaggle/input/mobilenet/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\",\n",
    "                                 include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "# Build Model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary classification (Healthy vs Glaucoma)\n",
    "])\n",
    "\n",
    "# Compile Model\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks (Early Stopping & Reduce LR on Plateau)\n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=17,\n",
    "    callbacks=[reduce_lr]\n",
    ")\n",
    "\n",
    "# Save Model\n",
    "model.save(\"mobilenetv2_glaucoma_model.keras\")\n",
    "\n",
    "print(\"Training completed and model saved!\")\n",
    "\n",
    "# Compute the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Make predictions on the validation set\n",
    "predictions = model.predict(val_data)  # Using validation set for predictions\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_classes = (predictions > 0.5).astype(\"int32\")  # Threshold at 0.5 for binary classification\n",
    "\n",
    "# Assuming val_data has the true labels as well\n",
    "true_labels = val_data.classes\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_classes)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "report = classification_report(true_labels, predicted_classes, target_names=['Healthy', 'Glaucoma'])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DENSENET121\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths\n",
    "dataset_path = \"/kaggle/input/glaucomadataset-healthy-and-infected-images/datasets combined\"\n",
    "batch_size = 16  # Adjust based on Kaggle memory limits\n",
    "img_size = (224, 224)  # Resize images for DenseNet\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # Splitting into training and validation\n",
    ")\n",
    "\n",
    "# Load training images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# Load validation images\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Define the correct path to your local weights file\n",
    "weights_path = \"/kaggle/input/dense121/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Load DenseNet121 model without the top layers (for feature extraction)\n",
    "base_model = tf.keras.applications.DenseNet121(\n",
    "    include_top=False,  # Remove the fully connected layers\n",
    "    input_shape=(224, 224, 3),  # Adjust the input shape if needed\n",
    "    weights=None  # Do not fetch from the internet\n",
    ")\n",
    "\n",
    "# Load the weights from the local file\n",
    "base_model.load_weights(weights_path)\n",
    "\n",
    "# Set the base model to not trainable (freeze it)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)  # Pooling layer to flatten the output\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)  # Fully connected layer\n",
    "x = tf.keras.layers.Dropout(0.5)(x)  # Dropout layer to reduce overfitting\n",
    "predictions = tf.keras.layers.Dense(1, activation='sigmoid')(x)  # 1 class: healthy or glaucoma (binary classification)\n",
    "\n",
    "# Final model\n",
    "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model with binary_crossentropy loss function\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy',  # Use binary_crossentropy for binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the generators\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=15,  # Set the number of epochs for training\n",
    "    validation_data=val_generator,\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
